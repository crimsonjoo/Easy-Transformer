{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 트랜스포머 디코더 구현하기\n",
        "[Crimsonjoo 깃허브](https://github.com/crimsonjoo/Easy-Transformer)\n",
        "\n",
        "이 노트북은 PyTorch를 사용하여 트랜스포머 모델의 디코더 부분을 구현하는 방법을 단계별로 설명합니다.\n",
        "\n",
        "트랜스포머 모델은 주로 자연어 처리(NLP) 분야에서 사용되는 모델로, 여러 개의 인코더와 디코더 레이어로 구성됩니다.\n",
        "\n",
        "해당 노트북에서는 디코더 부분만을 구현해보겠습니다.\n"
      ],
      "metadata": {
        "id": "-_MXXY1M_fDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "LVolkSTjD9rS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "8Jxd-LRpO6dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 필요한 라이브러리 불러오기\n",
        "\n",
        "먼저, 이 구현에 필요한 PyTorch 라이브러리를 불러옵니다."
      ],
      "metadata": {
        "id": "5tB7MBQd_mAF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ647gJ9-_IS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "1ZkRbTCgCEVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "rzXkryt2O61a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 디코더 구성 요소 구현하기\n",
        "\n",
        "트랜스포머 디코더를 구현하기 전에, 디코더가 사용하는 핵심 구성 요소들을 먼저 구현합니다.\n",
        "\n",
        "이 구성 요소들은 멀티 헤드 어텐션, 포지션 와이즈 피드포워드 네트워크, 그리고 레이어 노멀라이제이션입니다.\n"
      ],
      "metadata": {
        "id": "IEamfFDbC8My"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**1) 스케일드 닷 프로덕트 어텐션 함수**\n",
        "\n",
        "어텐션 메커니즘은 입력 시퀀스의 중요한 부분에 더 많은 주의를 기울이도록 모델을 돕습니다.\n",
        "\n",
        "\n",
        "스케일드 닷 프로덕트 어텐션은 이러한 어텐션 메커니즘의 한 형태입니다.\n"
      ],
      "metadata": {
        "id": "kHd1u0IPCHfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]  # 키 벡터의 차원\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)  # 스케일링\n",
        "    if mask is not None:\n",
        "        scaled += mask  # 마스크가 있으면 추가\n",
        "    attention = F.softmax(scaled, dim=-1)  # 소프트맥스를 통한 어텐션 가중치 계산\n",
        "    values = torch.matmul(attention, v)  # 가중치를 값 벡터에 적용\n",
        "    return values, attention"
      ],
      "metadata": {
        "id": "kcCyEP9VCHkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**2) 멀티 헤드 어텐션 클래스**\n",
        "\n",
        "멀티헤드 어텐션 클래스는 입력된 텍스트의 다양한 부분에 주의를 기울여 정보를 종합하는 데 도움을 줍니다.\n",
        "\n",
        "이를 통해 모델이 더 많은 맥락을 이해할 수 있게 됩니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "xpDpLu04DopZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 멀티헤드 어텐션\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        assert self.head_dim * num_heads == d_model, \"d_model의 차원 크기는 반드시 num_heads의 배수\"\n",
        "        self.qkv_layer = nn.Linear(d_model, 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, sequence_length, d_model = x.size()\n",
        "        qkv = self.qkv_layer(x).view(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3).chunk(3, dim=-1)\n",
        "        q, k, v = qkv\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        values = values.permute(0, 2, 1, 3).contiguous().view(batch_size, sequence_length, d_model)\n",
        "        out = self.linear_layer(values)\n",
        "        return out"
      ],
      "metadata": {
        "id": "xJBTzn1vDopZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**3) 포지션 와이즈 피드포워드 네트워크**\n",
        "\n",
        "이 네트워크는 각 위치에서 독립적으로 동작하는 전결합 레이어를 통해 정보를 처리합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "gX29b_hXMvty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위치별 전결합 피드포워드 네트워크\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hd0Zn0CEMvt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**4) 레이어 정규화**\n",
        "\n",
        "레이어 정규화는 각 레이어의 입력을 정규화하여 학습을 안정화시키는 기술입니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "A0b8B3DTD_b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이어 정규화\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        mean = inputs.mean(dim=-1, keepdim=True)\n",
        "        std = inputs.std(dim=-1, keepdim=True) + self.eps\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y + self.beta\n",
        "        return out"
      ],
      "metadata": {
        "id": "3y7QMGOqD_b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**5) 디코더 레이어 클래스**\n",
        "\n",
        "디코더 레이어는 멀티 헤드 어텐션과 포지션 와이즈 피드포워드 네트워크를 포함합니다.\n",
        "\n",
        "이 레이어는 입력 시퀀스를 변환하여 다음 레이어로 전달하는 역할을 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "iTK5nWO6D_8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 레이어\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.norm1 = LayerNormalization([d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model, ffn_hidden, drop_prob)\n",
        "        self.norm2 = LayerNormalization([d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, self_mask):\n",
        "        attention = self.self_attention(x, mask=self_mask)\n",
        "        x = self.norm1(x + self.dropout1(attention))\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = self.norm2(x + self.dropout2(ffn_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "QTXjz5rvD_8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**6) 디코더 클래스**\n",
        "\n",
        "이제 모든 구성 요소를 하나로 합쳐 디코더를 구성합니다.\n",
        "\n",
        "디코더는 여러 개의 디코더 레이어를 포함하며, 각 레이어는 입력 데이터를 처리하여 최종 출력을 생성합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "IDHp9ZWgEATq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 클래스\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "        self.norm = LayerNormalization([d_model])\n",
        "\n",
        "    def forward(self, x, self_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, self_mask)\n",
        "        x = self.norm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "90QapT7eEATq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "x-UwGMrSOMD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "3L5onpU0MrI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 모델 실행\n",
        "\n",
        "마지막으로, 디코더 모델을 초기화하고 입력 데이터에 대해 실행해보겠습니다.\n",
        "\n",
        "이를 통해 모델이 정상적으로 작동하는지 확인할 수 있습니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oglLcIxGOMED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 config\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "ffn_hidden = 2048\n",
        "num_layers = 5\n",
        "\n",
        "\n",
        "# 모델 선언\n",
        "x = torch.randn( (batch_size, max_sequence_length, d_model) ) # English sentence positional encoded\n",
        "y = torch.randn( (batch_size, max_sequence_length, d_model) ) # Korean sentence positional encoded\n",
        "mask = torch.full([max_sequence_length, max_sequence_length] , float('-inf'))\n",
        "mask = torch.triu(mask, diagonal=1)\n",
        "decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "\n",
        "\n",
        "# 모델 실행\n",
        "out = decoder(x, y, mask)"
      ],
      "metadata": {
        "id": "gLbxo0rmOMED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}