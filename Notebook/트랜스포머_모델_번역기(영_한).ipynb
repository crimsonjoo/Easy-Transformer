{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [영어-한국어 번역을 위한 Transformer 모델](https://github.com/crimsonjoo/Easy-Transformer/blob/main/Model/Transformer_translator_enkr.py)\n",
        "\n",
        "이 노트북은 영어 문장을 한국어로 번역하는 Transformer 모델을 구현하고 학습하는 과정을 단계별로 설명합니다.\n",
        "\n",
        "해당 Transformer 모델은 인코더와 디코더를 모두 사용합니다.\n",
        "\n",
        "또한, Wordbase 토크나이저 구조를 통해 영어와 한국어를 번역하는 매우 기본적인 번역 구조의 확인이 가능합니다.\n",
        "\n",
        "* 성능 고도화: BBPE(Byte-Level Byte Pair) SentencePiece 등의 토크나이저 사용 추천"
      ],
      "metadata": {
        "id": "-_MXXY1M_fDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "LVolkSTjD9rS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "8Jxd-LRpO6dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 필요한 라이브러리 불러오기\n",
        "\n",
        "먼저, 이 구현에 필요한 PyTorch 라이브러리를 불러옵니다."
      ],
      "metadata": {
        "id": "5tB7MBQd_mAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformer import Transformer"
      ],
      "metadata": {
        "id": "QTpoZsNWsPOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "1ZkRbTCgCEVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "Be_YbCertDFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터셋 준비\n",
        "\n",
        "영어와 한국어 문장 쌍이 포함된 데이터셋을 준비합니다. 이 예시에서는 데이터셋 파일 경로가 이미 정의되어 있다고 가정합니다.\n"
      ],
      "metadata": {
        "id": "DI7NnuDFtDFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_file = 'path/to/english_data.txt'\n",
        "korean_file = 'path/to/korean_data.txt'"
      ],
      "metadata": {
        "id": "060ual0ItDFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "rzXkryt2O61a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 어휘집(Vocabulary)과 토큰화(Tokenization)\n",
        "\n",
        "Transformer 모델에서는 각 언어별로 고유한 토큰들이 정의된 어휘집이 필요합니다.\n",
        "\n",
        "어휘집은 모델이 이해할 수 있는 형태로 문장을 변환하는 데 사용됩니다.\n",
        "\n",
        "\n",
        "실제 어플리케이션에서는 각 언어의 다양한 단어와 구두점, 특수 문자 등을 포함하는 훨씬 더 큰 어휘집이 필요합니다.\n",
        "\n",
        "여기서는 간단한 예시를 위해 축소된 어휘집을 사용합니다.\n"
      ],
      "metadata": {
        "id": "IEamfFDbC8My"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제 어플리케이션에서는 더 많은 토큰이 포함되어야 합니다.\n",
        "# Token (추후 개선: BBPE SentencePiece)\n",
        "START_TOKEN = '<start>'\n",
        "PADDING_TOKEN = '<pad>'\n",
        "END_TOKEN = '<end>'\n",
        "\n",
        "\n",
        "\n",
        "english_vocabulary = [START_TOKEN, PADDING_TOKEN, END_TOKEN, ...]\n",
        "korean_vocabulary = [START_TOKEN, PADDING_TOKEN, END_TOKEN, ...]\n",
        "\n",
        "# 어휘집에서 토큰과 인덱스 사이의 매핑 생성\n",
        "english_to_index = {token: index for index, token in enumerate(english_vocabulary)}\n",
        "index_to_english = {index: token for index, token in enumerate(english_vocabulary)}\n",
        "korean_to_index = {token: index for index, token in enumerate(korean_vocabulary)}\n",
        "index_to_korean = {index: token for index, token in enumerate(korean_vocabulary)}"
      ],
      "metadata": {
        "id": "Ov_ofLXys8LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "u897q4gNtEEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 데이터셋 클래스 정의\n",
        "\n",
        "PyTorch의 `Dataset` 클래스를 상속받아, 우리의 번역 데이터셋을 위한 커스텀 데이터셋 클래스를 정의합니다.\n",
        "\n",
        "이 클래스는 모델 학습에 필요한 데이터를 적절히 로딩하고 전처리하는 역할을 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "oXKlQok4zIvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, source_sentences, target_sentences, src_vocab, tgt_vocab):\n",
        "        self.source_sentences = source_sentences\n",
        "        self.target_sentences = target_sentences\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_sentence = self.source_sentences[idx]\n",
        "        tgt_sentence = self.target_sentences[idx]\n",
        "        src_indices = [self.src_vocab[token] if token in self.src_vocab else self.src_vocab['<pad>'] for token in src_sentence.split(' ')]\n",
        "        tgt_indices = [self.tgt_vocab[token] if token in self.tgt_vocab else self.tgt_vocab['<pad>'] for token in tgt_sentence.split(' ')]\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n",
        "\n",
        "\n",
        "# 데이터셋 로딩 및 전처리\n",
        "def load_and_preprocess_data(src_file, tgt_file):\n",
        "    with open(src_file, 'r', encoding='utf-8') as f:\n",
        "        src_sentences = f.readlines()\n",
        "    with open(tgt_file, 'r', encoding='utf-8') as f:\n",
        "        tgt_sentences = f.readlines()\n",
        "    src_sentences = [line.strip() for line in src_sentences]\n",
        "    tgt_sentences = [line.strip() for line in tgt_sentences]\n",
        "    return src_sentences, tgt_sentences\n",
        "\n",
        "\n",
        "# 데이터셋 및 데이터로더 선언\n",
        "english_sentences, korean_sentences = load_and_preprocess_data(english_file, korean_file)\n",
        "dataset = TranslationDataset(english_sentences, korean_sentences, english_to_index, korean_to_index)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "PeVcWb2wzIvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "zZPdFxY9zIvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 모델 정의\n",
        "\n",
        "Transformer 모델을 정의합니다.\n",
        "모델은 영어 문장을 입력으로 받아 해당하는 한국어 문장을 출력합니다.\n"
      ],
      "metadata": {
        "id": "OUUNtMJ5tEEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
        "        scaled = scaled.permute(1, 0, 2, 3)\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = (torch.arange(self.max_sequence_length)\n",
        "                          .reshape(self.max_sequence_length, 1))\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE\n",
        "\n",
        "class SentenceEmbedding(nn.Module):\n",
        "    \"For a given sentence, create an embedding\"\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.vocab_size = len(language_to_index)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "\n",
        "    def batch_tokenize(self, batch, start_token, end_token):\n",
        "\n",
        "        def tokenize(sentence, start_token, end_token):\n",
        "            sentence_word_indicies = [self.language_to_index[token] for token in list(sentence)]\n",
        "            if start_token:\n",
        "                sentence_word_indicies.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "            if end_token:\n",
        "                sentence_word_indicies.append(self.language_to_index[self.END_TOKEN])\n",
        "            for _ in range(len(sentence_word_indicies), self.max_sequence_length):\n",
        "                sentence_word_indicies.append(self.language_to_index[self.PADDING_TOKEN])\n",
        "            return torch.tensor(sentence_word_indicies)\n",
        "\n",
        "        tokenized = []\n",
        "        for sentence_num in range(len(batch)):\n",
        "           tokenized.append( tokenize(batch[sentence_num], start_token, end_token) )\n",
        "        tokenized = torch.stack(tokenized)\n",
        "        return tokenized.to(get_device())\n",
        "\n",
        "    def forward(self, x, start_token, end_token): # sentence\n",
        "        x = self.batch_tokenize(x, start_token, end_token)\n",
        "        x = self.embedding(x)\n",
        "        pos = self.position_encoder().to(get_device())\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, sequence_length, d_model = x.size()\n",
        "        qkv = self.qkv_layer(x)\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y + self.beta\n",
        "        return out\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, self_attention_mask):\n",
        "        residual_x = x.clone()\n",
        "        x = self.attention(x, mask=self_attention_mask)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + residual_x)\n",
        "        residual_x = x.clone()\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.norm2(x + residual_x)\n",
        "        return x\n",
        "\n",
        "class SequentialEncoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, self_attention_mask  = inputs\n",
        "        for module in self._modules.values():\n",
        "            x = module(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                      for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, self_attention_mask, start_token, end_token):\n",
        "        x = self.sentence_embedding(x, start_token, end_token)\n",
        "        x = self.layers(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        batch_size, sequence_length, d_model = x.size() # in practice, this is the same for both languages...so we can technically combine with normal attention\n",
        "        kv = self.kv_layer(x)\n",
        "        q = self.q_layer(y)\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
        "        kv = kv.permute(0, 2, 1, 3)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k, v = kv.chunk(2, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) # We don't need the mask for cross attention, removing in outer function!\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
        "        _y = y.clone()\n",
        "        y = self.self_attention(y, mask=self_attention_mask)\n",
        "        y = self.dropout1(y)\n",
        "        y = self.layer_norm1(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
        "        y = self.dropout2(y)\n",
        "        y = self.layer_norm2(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.ffn(y)\n",
        "        y = self.dropout3(y)\n",
        "        y = self.layer_norm3(y + _y)\n",
        "        return y\n",
        "\n",
        "\n",
        "class SequentialDecoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
        "        for module in self._modules.values():\n",
        "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token):\n",
        "        y = self.sentence_embedding(y, start_token, end_token)\n",
        "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_model,\n",
        "                ffn_hidden,\n",
        "                num_heads,\n",
        "                drop_prob,\n",
        "                num_layers,\n",
        "                max_sequence_length,\n",
        "                kn_vocab_size,\n",
        "                english_to_index,\n",
        "                kannada_to_index,\n",
        "                START_TOKEN,\n",
        "                END_TOKEN,\n",
        "                PADDING_TOKEN\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, english_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, kannada_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.linear = nn.Linear(d_model, kn_vocab_size)\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    def forward(self,\n",
        "                x,\n",
        "                y,\n",
        "                encoder_self_attention_mask=None,\n",
        "                decoder_self_attention_mask=None,\n",
        "                decoder_cross_attention_mask=None,\n",
        "                enc_start_token=False,\n",
        "                enc_end_token=False,\n",
        "                dec_start_token=False, # We should make this true\n",
        "                dec_end_token=False): # x, y are batch of sentences\n",
        "        x = self.encoder(x, encoder_self_attention_mask, start_token=enc_start_token, end_token=enc_end_token)\n",
        "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token=dec_start_token, end_token=dec_end_token)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "cvAo6FoatEEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer 모델 선언\n",
        "transformer = Transformer(\n",
        "    d_model=512,\n",
        "    ffn_hidden=2048,\n",
        "    num_heads=8,\n",
        "    drop_prob=0.1,\n",
        "    num_layers=6,\n",
        "    max_sequence_length=200,\n",
        "    source_vocab_size=len(english_vocabulary),\n",
        "    target_vocab_size=len(korean_vocabulary),\n",
        "    target_pad_idx=korean_to_index[PADDING_TOKEN],\n",
        "    source_pad_idx=english_to_index[PADDING_TOKEN]\n",
        ")"
      ],
      "metadata": {
        "id": "VPiyAsWnyjNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "PXbNByNftEn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 모델 학습\n",
        "\n",
        "학습 데이터를 사용하여 모델을 학습시킵니다.\n",
        "\n",
        "이 과정에서 모델은 영어 문장과 그에 해당하는 한국어 번역 사이의 매핑을 학습합니다.\n"
      ],
      "metadata": {
        "id": "27uATOLptEn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 로직\n",
        "def train(model, data_loader, epochs=10):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=korean_to_index['<pad>'])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src_indices, tgt_indices in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src_indices, tgt_indices[:, :-1])  # 마지막 <end> 토큰을 제외한 타겟 문장\n",
        "            loss = criterion(output.view(-1, model.target_vocab_size), tgt_indices[:, 1:].reshape(-1))  # 첫 <start> 토큰을 제외한 타겟 문장\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}\")\n",
        "\n",
        "\n",
        "# 학습을 시작합니다.\n",
        "train(transformer, train_loader)"
      ],
      "metadata": {
        "id": "jmr0Zg4WtEn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "GwYc2xaGt73n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 모델 평가\n",
        "\n",
        "학습된 모델을 사용하여 새로운 영어 문장의 한국어 번역을 생성합니다.\n"
      ],
      "metadata": {
        "id": "cQQOChJTt73w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 로직을 정의합니다. 실제 번역 결과를 생성하고 평가하는 과정이 포함됩니다.\n",
        "def translate(model, src_sentence, src_vocab, tgt_vocab, max_length=50):\n",
        "    model.eval()\n",
        "    src_indices = [src_vocab[token] if token in src_vocab else src_vocab['<pad>'] for token in src_sentence.split(' ')]\n",
        "    src_tensor = torch.tensor(src_indices).unsqueeze(0)\n",
        "    tgt_indices = [tgt_vocab['<start>']]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            output = model(src_tensor, tgt_tensor)\n",
        "        next_token_index = output.argmax(2)[:,-1].item()\n",
        "        tgt_indices.append(next_token_index)\n",
        "        if next_token_index == tgt_vocab['<end>']:\n",
        "            break\n",
        "\n",
        "    translated_sentence = ' '.join([index_to_korean[idx] for idx in tgt_indices[1:-1]])  # <start>와 <end> 토큰 제외\n",
        "    return translated_sentence\n",
        "\n",
        "\n",
        "# 모델 훈련\n",
        "train(transformer, data_loader)\n",
        "\n",
        "\n",
        "# 테스트 문장 번역\n",
        "test_sentence = \"Hello world!\"\n",
        "print(\"영어:\", test_sentence)\n",
        "print(\"번역된 한국어:\", translate(transformer, test_sentence, english_to_index, korean_to_index))"
      ],
      "metadata": {
        "id": "xuVfP_jQt73w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "0uhN5wk-uLGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "vAYuc7ZXuiPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NykGiZPfuLJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실제 어플리케이션에서의 고려사항\n",
        "\n",
        "위 예시에서는 간소화된 어휘집을 사용했지만, 실제 어플리케이션에서는 훨씬 더 다양하고 복잡한 어휘가 사용됩니다. 또한, 실제 텍스트에서는 드물게 사용되는 단어나 표현도 포함될 수 있어, 모델이 이를 잘 처리할 수 있도록 충분히 크고 다양한 데이터셋으로 학습시키는 것이 중요합니다.\n",
        "\n",
        "더 나아가, 효율적인 어휘집 관리와 모델의 일반화 능력을 향상시키기 위해, Byte Pair Encoding(BPE)이나 SentencePiece 같은 고급 토크나이징 방법을 사용할 수 있습니다. 이 방법들은 희귀 단어를 하위 단위(subword units)로 분해하여 처리함으로써, 모델이 미처본 단어에도 강건하게 대응할 수 있게 합니다.\n",
        "\n",
        "이러한 고려사항들은 모델의 성능과 범용성을 크게 향상시킬 수 있으며,"
      ],
      "metadata": {
        "id": "q_-TAD0p5D59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "HQJJrb6s7KIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BPE와 SentencePiece의 중요성\n",
        "\n",
        "### - BPE(Byte Pair Encoding)\n",
        ":BPE는 데이터에서 가장 자주 나타나는 바이트 쌍을 반복적으로 병합하여 어휘집을 구성하는 방식입니다. 이 방법은 초기에 데이터 압축 알고리즘으로 개발되었지만, 후에 자연어 처리에서 효율적인 서브워드 토큰화 방법으로 사용되고 있습니다. BPE를 사용하면, 어휘집의 크기를 고정하면서도 희귀 단어를 효과적으로 처리할 수 있으며, 새로운 단어나 외래어에 대한 모델의 대응 능력을 향상시킬 수 있습니다.\n",
        "\n",
        "### - SentencePiece\n",
        ":SentencePiece는 언어에 의존하지 않는 모델 학습을 위한 토큰화 도구입니다. 이 도구는 BPE와 유사한 방식으로 작동하지만, 언어의 사전 지식 없이도 사용할 수 있다는 장점이 있습니다. SentencePiece는 원시 텍스트 데이터로부터 직접 서브워드 단위로 토큰화를 수행하며, 이 과정에서 공백 정보도 함께 학습합니다. 이는 다양한 언어와 도메인에 걸쳐 모델의 일반화 능력을 향상시키는 데 도움을 줍니다."
      ],
      "metadata": {
        "id": "xcc1oVMj6Qyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "ImyPq8WL67h7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델의 일반화 능력 향상\n",
        "\n",
        "위에서 설명한 토크나이징 방법 외에도, 효과적인 데이터 전처리, 데이터 증강, 모델 정규화 기법 등 다양한 방법을 통해 모델의 일반화 능력을 향상시킬 수 있습니다. 이러한 기법들은 모델이 학습 데이터에만 과도하게 적응하는 것을 방지하고, 실제 세계에서 발생할 수 있는 다양한 시나리오에 더 잘 대응할 수 있도록 만듭니다.\n"
      ],
      "metadata": {
        "id": "RbYgESOz6oeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;"
      ],
      "metadata": {
        "id": "GmlTGOmk671R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결론\n",
        "\n",
        "영어-한국어어 번역기를 비롯한 자연어 처리 모델을 개발할 때, 단순히 모델의 구조만이 아니라 데이터의 특성과 전처리, 토큰화 방법, 모델의 일반화 능력 등 다양한 요소들을 종합적으로 고려해야 합니다. 이러한 과정을 통해 더욱 정확하고 범용적인 자연어 처리 시스템을 구축할 수 있습니다. 초보자들이 이 분야에 입문할 때, 이러한 다양한 요소들을 이해하고 실험해 보는 것이 매우 중요합니다."
      ],
      "metadata": {
        "id": "aM8LNRjj6ok2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "01JenKkJuLLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "효율적인 어휘집 관리와 모델의 일반화 능력을 향상시키기 위해, Byte Pair Encoding(BPE)이나 SentencePiece 같은 고급 토크나이징 방법을 사용할 수 있습니다. 이 방법들은 희귀 단어를 하위 단위(subword units)로 분해하여 처리함으로써, 모델이 미처본 단어에도 강건하게 대응할 수 있게 합니다.\n",
        "\n",
        "이러한 고려사항들은 모델의 성능과 범용성을 크게 향상시킬 수 있으며, 이러한 토크나이저들을 사용함으로써, 모델은 더 넓은 범위의 언어적 다양성을 이해하고,실제 사용자가 입력할 수 있는 다양한 문장에 대해 더 정확한 번역을 제공할 수 있습니다."
      ],
      "metadata": {
        "id": "059GiLviulxv"
      }
    }
  ]
}